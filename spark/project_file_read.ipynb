{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707d2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f09ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2431242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pendulum as pdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e89877",
   "metadata": {},
   "source": [
    "# inputs\n",
    "- city\n",
    "- fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db295039",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'san_francisco'\n",
    "fname = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d435ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for city-specific data\n",
    "cities = ['Chicago', 'San Francisco', 'Los Angeles', 'Austin']\n",
    "f_cities = [c.replace(' ', '_').lower() for c in cities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8c447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_bkt = os.getenv('GCP_GCS_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3026f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "jar_path = os.getenv('JAR_FILE_LOC')\n",
    "creds_path = '/.google/credentials/' + os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('proj_file_read') \\\n",
    "    .set(\"spark.jars\", jar_path) \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", creds_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b43a2e",
   "metadata": {},
   "source": [
    "### Only if an existing one already runs:\n",
    "`sc.stop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624e4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/26 15:29:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a3fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hconf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hconf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hconf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hconf.set(\"fs.gs.auth.service.account.json.keyfile\", creds_path)\n",
    "hconf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e9c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081160d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce8ddf3",
   "metadata": {},
   "source": [
    "### first, open dataset page and check data dictionary on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4bbef",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 1-time sample download for pandas reading to infer schema for everything else:\n",
    "\n",
    "command:\n",
    "`!wget https://data.cityofchicago.org/api/views/hx8q-mf9v/rows.csv?accessType=DOWNLOAD`\n",
    "\n",
    "note: file is `Crimes_-_2012.csv`\n",
    "\n",
    "output:\n",
    "```\n",
    "--2022-10-22 08:53:42--  https://data.cityofchicago.org/api/views/hx8q-mf9v/rows.csv?accessType=DOWNLOAD\n",
    "Resolving data.cityofchicago.org (data.cityofchicago.org)... 52.206.140.205, 52.206.68.26, 52.206.140.199\n",
    "Connecting to data.cityofchicago.org (data.cityofchicago.org)|52.206.140.205|:443... connected.\n",
    "HTTP request sent, awaiting response... 200 OK\n",
    "Length: unspecified [text/csv]\n",
    "Saving to: ‘rows.csv?accessType=DOWNLOAD’\n",
    "\n",
    "rows.csv?accessType     [          <=>       ]  75.99M  2.54MB/s    in 28s     \n",
    "\n",
    "2022-10-22 08:54:11 (2.68 MB/s) - ‘rows.csv?accessType=DOWNLOAD’ saved [79677853]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b10f9258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-26 18:04:39--  https://data.sfgov.org/api/views/tmnf-yvry/rows.csv?accessType=DOWNLOAD\n",
      "Resolving data.sfgov.org (data.sfgov.org)... 52.206.140.199, 52.206.140.205, 52.206.68.26\n",
      "Connecting to data.sfgov.org (data.sfgov.org)|52.206.140.199|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‘rows.csv?accessType=DOWNLOAD.2’\n",
      "\n",
      "rows.csv?accessType     [          <=>       ] 525.42M  3.79MB/s    in 2m 31s  \n",
      "\n",
      "2022-10-26 18:07:11 (3.48 MB/s) - ‘rows.csv?accessType=DOWNLOAD.2’ saved [550945238]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://data.sfgov.org/api/views/tmnf-yvry/rows.csv?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf5a7c",
   "metadata": {},
   "source": [
    "### check count here: raw csv file\n",
    "command:\n",
    "`!wc -l rows.csv?accessType=DOWNLOAD`\n",
    "\n",
    "chicago1: `485854 rows.csv?accessType=DOWNLOAD`\n",
    "chicago12: `336247 rows.csv?accessType=DOWNLOAD`\n",
    "austin: `35098 rows.csv?accessType=DOWNLOAD.1`\n",
    "los angeles: ` `\n",
    "san francisco: `2129526 rows.csv?accessType=DOWNLOAD.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c142a4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2129526 rows.csv?accessType=DOWNLOAD.2\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l rows.csv?accessType=DOWNLOAD.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3988734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PdId', 'IncidntNum', 'Incident Code', 'Category', 'Descript',\n",
       "       'DayOfWeek', 'Date', 'Time', 'PdDistrict', 'Resolution', 'Address', 'X',\n",
       "       'Y', 'location', 'SF Find Neighborhoods 2 2',\n",
       "       'Current Police Districts 2 2', 'Current Supervisor Districts 2 2',\n",
       "       'Analysis Neighborhoods 2 2', 'DELETE - Fire Prevention Districts 2 2',\n",
       "       'DELETE - Police Districts 2 2', 'DELETE - Supervisor Districts 2 2',\n",
       "       'DELETE - Zip Codes 2 2', 'DELETE - Neighborhoods 2 2',\n",
       "       'DELETE - 2017 Fix It Zones 2 2',\n",
       "       'Civic Center Harm Reduction Project Boundary 2 2',\n",
       "       'Fix It Zones as of 2017-11-06  2 2', 'DELETE - HSOC Zones 2 2',\n",
       "       'Fix It Zones as of 2018-02-07 2 2',\n",
       "       'CBD, BID and GBD Boundaries as of 2017 2 2',\n",
       "       'Areas of Vulnerability, 2016 2 2',\n",
       "       'Central Market/Tenderloin Boundary 2 2',\n",
       "       'Central Market/Tenderloin Boundary Polygon - Updated 2 2',\n",
       "       'HSOC Zones as of 2018-06-05 2 2', 'OWED Public Spaces 2 2',\n",
       "       'Neighborhoods 2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd = pd.read_csv('rows.csv?accessType=DOWNLOAD.2', nrows=1000)\n",
    "df_pd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebdbfb",
   "metadata": {},
   "source": [
    "### see sample of data\n",
    "Command: `df_pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99e75bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             PdId  IncidntNum  Incident Code       Category  \\\n",
      "0   4133422003074    41334220           3074        ROBBERY   \n",
      "1   5118535807021    51185358           7021  VEHICLE THEFT   \n",
      "2   4018830907021    40188309           7021  VEHICLE THEFT   \n",
      "3  11014543126030   110145431          26030          ARSON   \n",
      "4  10108108004134   101081080           4134        ASSAULT   \n",
      "\n",
      "                Descript DayOfWeek        Date   Time PdDistrict Resolution  \\\n",
      "0  ROBBERY, BODILY FORCE    Monday  11/22/2004  17:50  INGLESIDE       NONE   \n",
      "1      STOLEN AUTOMOBILE   Tuesday  10/18/2005  20:00       PARK       NONE   \n",
      "2      STOLEN AUTOMOBILE    Sunday  02/15/2004  02:00   SOUTHERN       NONE   \n",
      "3                  ARSON    Friday  02/18/2011  05:27  INGLESIDE       NONE   \n",
      "4                BATTERY    Sunday  11/21/2010  17:00   SOUTHERN       NONE   \n",
      "\n",
      "   ... Fix It Zones as of 2017-11-06  2 2  DELETE - HSOC Zones 2 2  \\\n",
      "0  ...                                NaN                      NaN   \n",
      "1  ...                                NaN                      NaN   \n",
      "2  ...                                NaN                      NaN   \n",
      "3  ...                                NaN                      NaN   \n",
      "4  ...                                NaN                      NaN   \n",
      "\n",
      "   Fix It Zones as of 2018-02-07 2 2  \\\n",
      "0                                NaN   \n",
      "1                                NaN   \n",
      "2                                NaN   \n",
      "3                                NaN   \n",
      "4                                NaN   \n",
      "\n",
      "  CBD, BID and GBD Boundaries as of 2017 2 2  \\\n",
      "0                                        NaN   \n",
      "1                                        NaN   \n",
      "2                                        NaN   \n",
      "3                                        NaN   \n",
      "4                                        NaN   \n",
      "\n",
      "   Areas of Vulnerability, 2016 2 2  Central Market/Tenderloin Boundary 2 2  \\\n",
      "0                               NaN                                     NaN   \n",
      "1                               NaN                                     NaN   \n",
      "2                               NaN                                     NaN   \n",
      "3                               1.0                                     NaN   \n",
      "4                               2.0                                     NaN   \n",
      "\n",
      "   Central Market/Tenderloin Boundary Polygon - Updated 2 2  \\\n",
      "0                                                       NaN   \n",
      "1                                                       NaN   \n",
      "2                                                       NaN   \n",
      "3                                                       NaN   \n",
      "4                                                       NaN   \n",
      "\n",
      "   HSOC Zones as of 2018-06-05 2 2  OWED Public Spaces 2 2  Neighborhoods 2  \n",
      "0                              NaN                     NaN              NaN  \n",
      "1                              NaN                     NaN              NaN  \n",
      "2                              NaN                     NaN              NaN  \n",
      "3                              NaN                     NaN             94.0  \n",
      "4                              NaN                     NaN             32.0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', None)\n",
    "print(df_pd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee772d",
   "metadata": {},
   "source": [
    "### initial commands for all (1 cell each)\n",
    "Commands:\n",
    "```\n",
    "df_pd = pd.read_csv('rows.csv?accessType=DOWNLOAD.1', nrows=1000)\n",
    "df_pd.columns\n",
    "```\n",
    "get output, then:\n",
    "```\n",
    "spark.createDataFrame(df_pd).schema\n",
    "```\n",
    "if with error, then:\n",
    "```\n",
    "cols = <PASTE COLUMN LIST HERE, REMOVE PROBLEMATIC COL>\n",
    "\n",
    "df_pd = pd.read_csv('<EDIT FILENAME>', nrows=1000, usecols=cols)\n",
    "```\n",
    "\n",
    "### for Chicago because of `TypeError: Can not merge type (pandas string to spark double) for 'Location Description', 'location' fields`\n",
    "```\n",
    "cols = ['Case Number', 'Date', 'Block', 'IUCR', 'Primary Type', 'Description', 'Arrest', 'Domestic', 'Beat', 'Ward', 'FBI Code', 'X Coordinate', 'Y Coordinate', 'Year', 'Latitude', 'Longitude']\n",
    "```\n",
    "\n",
    "### for Austin because of `TypeError: Can not merge type (pandas string to spark double) for 'Clearance Status', 'Clearance Date', 'GO Location' fields`\n",
    "Commands:\n",
    "```\n",
    "cols = ['GO Primary Key', 'Council District', 'GO Highest Offense Desc', 'Highest NIBRS/UCR Offense Description', 'GO Report Date', 'GO District', 'GO Location Zip', 'GO Census Tract', 'GO X Coordinate', 'GO Y Coordinate']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5977e52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('PdId', LongType(), True), StructField('IncidntNum', LongType(), True), StructField('Incident Code', LongType(), True), StructField('Category', StringType(), True), StructField('Descript', StringType(), True), StructField('DayOfWeek', StringType(), True), StructField('Date', StringType(), True), StructField('Time', StringType(), True), StructField('PdDistrict', StringType(), True), StructField('Resolution', StringType(), True), StructField('Address', StringType(), True), StructField('X', DoubleType(), True), StructField('Y', DoubleType(), True), StructField('location', StringType(), True), StructField('SF Find Neighborhoods 2 2', DoubleType(), True), StructField('Current Police Districts 2 2', DoubleType(), True), StructField('Current Supervisor Districts 2 2', DoubleType(), True), StructField('Analysis Neighborhoods 2 2', DoubleType(), True), StructField('DELETE - Fire Prevention Districts 2 2', DoubleType(), True), StructField('DELETE - Police Districts 2 2', DoubleType(), True), StructField('DELETE - Supervisor Districts 2 2', DoubleType(), True), StructField('DELETE - Zip Codes 2 2', DoubleType(), True), StructField('DELETE - Neighborhoods 2 2', DoubleType(), True), StructField('DELETE - 2017 Fix It Zones 2 2', DoubleType(), True), StructField('Civic Center Harm Reduction Project Boundary 2 2', DoubleType(), True), StructField('Fix It Zones as of 2017-11-06  2 2', DoubleType(), True), StructField('DELETE - HSOC Zones 2 2', DoubleType(), True), StructField('Fix It Zones as of 2018-02-07 2 2', DoubleType(), True), StructField('CBD, BID and GBD Boundaries as of 2017 2 2', DoubleType(), True), StructField('Areas of Vulnerability, 2016 2 2', DoubleType(), True), StructField('Central Market/Tenderloin Boundary 2 2', DoubleType(), True), StructField('Central Market/Tenderloin Boundary Polygon - Updated 2 2', DoubleType(), True), StructField('HSOC Zones as of 2018-06-05 2 2', DoubleType(), True), StructField('OWED Public Spaces 2 2', DoubleType(), True), StructField('Neighborhoods 2', DoubleType(), True)])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pd).schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e7c07",
   "metadata": {},
   "source": [
    "### modify schema output above and removed columns, based on sample output before, then add template below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3935473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified pattern from pandas schema\n",
    "if city == f_cities[0]:\n",
    "    schema_template = types.StructType([\n",
    "        types.StructField('Case Number', types.StringType(), True),\n",
    "        types.StructField('Date', types.StringType(), True),\n",
    "        types.StructField('Block', types.StringType(), True),\n",
    "        types.StructField('IUCR', types.StringType(), True),\n",
    "        types.StructField('Primary Type', types.StringType(), True),\n",
    "        types.StructField('Description', types.StringType(), True),\n",
    "        types.StructField('Location Description', types.StringType(), True),\n",
    "        types.StructField('Arrest', types.BooleanType(), True),\n",
    "        types.StructField('Domestic', types.BooleanType(), True),\n",
    "        types.StructField('Beat', types.StringType(), True),\n",
    "        types.StructField('Ward', types.IntegerType(), True),\n",
    "        types.StructField('FBI Code', types.StringType(), True),\n",
    "        types.StructField('X Coordinate', types.FloatType(), True),\n",
    "        types.StructField('Y Coordinate', types.FloatType(), True),\n",
    "        types.StructField('Year', types.IntegerType(), True),\n",
    "        types.StructField('Latitude', types.FloatType(), True),\n",
    "        types.StructField('Longitude', types.FloatType(), True),\n",
    "        types.StructField('Location', types.StringType(), True)\n",
    "    ])\n",
    "elif city == f_cities[1]:\n",
    "    pass\n",
    "elif city == f_cities[3]:\n",
    "    schema_template = types.StructType([\n",
    "    types.StructField('GO Primary Key', types.IntegerType(), True),\n",
    "    types.StructField('Council District', types.IntegerType(), True),\n",
    "    types.StructField('GO Highest Offense Desc', types.StringType(), True),\n",
    "    types.StructField('Highest NIBRS/UCR Offense Description', types.StringType(), True),\n",
    "    types.StructField('GO Report Date', types.StringType(), True),\n",
    "    types.StructField('GO Location', types.StringType(), True),\n",
    "    types.StructField('Clearance Status', types.StringType(), True),\n",
    "    types.StructField('Clearance Date', types.StringType(), True),\n",
    "    types.StructField('GO District', types.StringType(), True),\n",
    "    types.StructField('GO Location Zip', types.IntegerType(), True),\n",
    "    types.StructField('GO Census Tract', types.FloatType(), True),\n",
    "    types.StructField('GO X Coordinate', types.IntegerType(), True),\n",
    "    types.StructField('GO Y Coordinate', types.IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53fe796",
   "metadata": {},
   "source": [
    "### Replace below with me:\n",
    "```\n",
    "df_csv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema_template) \\\n",
    "    .csv(f'{gcs_bkt}/raw/{city}/{fname}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "377b7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema_template) \\\n",
    "    .csv(f'{gcs_bkt}/raw/{city}/' + '2017_Annual_Crime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32861bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35097"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1dd45",
   "metadata": {},
   "source": [
    "### check count here: original df\n",
    "Command:\n",
    "`df_csv.count()`\n",
    "\n",
    "Output:\n",
    "`485853`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be2c77",
   "metadata": {},
   "source": [
    "### inspect data\n",
    "Command:\n",
    "```\n",
    "df_csv.head(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63866a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dt(dt_str):\n",
    "    \"\"\"\n",
    "    parse datetime object from given date string of specific format\n",
    "    \"\"\"\n",
    "    if city == f_cities[0]:\n",
    "        fmt = 'MM/DD/YYYY HH:mm:ss A'\n",
    "    elif city == f_cities[3]:\n",
    "        fmt = 'D-MMM-YY'\n",
    "    return pdl.from_format(dt_str, fmt)\n",
    "\n",
    "parse_dt_udf = F.udf(parse_dt, returnType=types.TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b57c558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parse datetime out of provided date column\n",
    "dt_str_col = {f_cities[0]: 'Date', f_cities[3]: 'GO Report Date'}\n",
    "df_time = df_csv.withColumn('Timestamp', parse_dt_udf(F.col(dt_str_col[city])))\n",
    "\n",
    "if city == f_cities[0]:\n",
    "    years_rows = df_time \\\n",
    "        .select('Year')\n",
    "elif city == f_cities[3]:\n",
    "    years_rows = df_time \\\n",
    "        .select(F.year('Timestamp').alias('Year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b8224ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "years_rows = years_rows \\\n",
    "    .dropna() \\\n",
    "    .dropDuplicates(['Year']) \\\n",
    "    .collect()\n",
    "\n",
    "years = [row.Year for row in years_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685264d3",
   "metadata": {},
   "source": [
    "### check parsed years\n",
    "Command:\n",
    "`print(years)`\n",
    "\n",
    "Output:\n",
    "`[2001]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef055959",
   "metadata": {},
   "source": [
    "### check count Jan: csv df, strdate col\n",
    "Command: Chicago\n",
    "```\n",
    "df_time \\\n",
    "    .filter(F.month('Timestamp') == 1) \\\n",
    "    .count()\n",
    "```\n",
    "Chicago: `38114` Austin: `3098`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "90c8a397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time \\\n",
    "    .filter(F.month('Timestamp') == 1) \\\n",
    "    .filter(F.dayofmonth('Timestamp') == 1) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d81a0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### check date Jan1: csv df, strdate col\n",
    "Command: Chicago\n",
    "```\n",
    "df_time \\\n",
    "    .filter(F.month('Timestamp') == 1) \\\n",
    "    .filter(F.dayofmonth('Timestamp') == 1) \\\n",
    "    .count()\n",
    "```\n",
    "Chicago: `1825` Austin: `97`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b594ca37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "o_cols = df_time.columns\n",
    "cols = [col.lower().replace(' ', '_') for col in o_cols]\n",
    "\n",
    "for year in years:\n",
    "    df = df_time.filter(F.year('Timestamp') == year)\n",
    "    for month in range(1, 13):\n",
    "        df_month = df.filter(F.month('Timestamp') == month)\n",
    "        for i in range(len(o_cols)):\n",
    "            df_month = df_month.withColumnRenamed(o_cols[i], cols[i])\n",
    "        df_month \\\n",
    "            .drop('Timestamp', dt_str_col[city]) \\\n",
    "            .write.parquet(f'{gcs_bkt}/pq/{city}/{year}/{month}', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
