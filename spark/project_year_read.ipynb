{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707d2ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2431242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e89877",
   "metadata": {},
   "source": [
    "# inputs\n",
    "- year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db295039",
   "metadata": {},
   "outputs": [],
   "source": [
    "from city_vars import dict_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9285f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_proper = 'Austin'\n",
    "year = '2015'\n",
    "month = '5'\n",
    "dict_city = dict_cities[city_proper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8c447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bkt = os.getenv('GCP_GCS_BUCKET')\n",
    "jar_path = os.getenv('JAR_FILE_LOC')\n",
    "creds_path = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b3026f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional ignore flag at end for cities with no data for year\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('spark://project-spark-1:7077') \\\n",
    "    .setAppName('project_year_read') \\\n",
    "    .set(\"spark.jars\", jar_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b43a2e",
   "metadata": {},
   "source": [
    "### Only if an existing one already runs:\n",
    "`sc.stop()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624e4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/03 10:22:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a3fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hconf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hconf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hconf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hconf.set(\"fs.gs.auth.service.account.json.keyfile\", creds_path)\n",
    "hconf.set(\"fs.gs.auth.service.account.enable\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e9c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081160d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc68c07",
   "metadata": {},
   "source": [
    "### Replace below with me:\n",
    "```\n",
    "dict_df = {}\n",
    "for city in cities:\n",
    "    df_pq = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(, ) \\\n",
    "        .parquet(f'{gcs_bkt}/pq/{city}/{year}/*')\n",
    "    dict_df.update({city: df_pq})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c58ce765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_pq = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet(f\"{gs_bkt}/pq/from_raw/{dict_city['formatted']}/{year}/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11db061",
   "metadata": {},
   "source": [
    "### check count here: pq df\n",
    "Command: `df_pq.count()`\n",
    "\n",
    "Output: `485853`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out duplicates\n",
    "# filter out rows with null values in important columns\n",
    "# add timestamp column\n",
    "df_time = df_pq \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d3289",
   "metadata": {},
   "source": [
    "### check count here: non-null df\n",
    "Command:\n",
    "`df_time.count()`\n",
    "\n",
    "Output:\n",
    "`38114`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f37b74",
   "metadata": {},
   "source": [
    "### check parsed dates\n",
    "\n",
    "Command: `df_time.head(10)`\n",
    "\n",
    "Output: must contain datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a55b3d7",
   "metadata": {},
   "source": [
    "### check date here: csv df, datetime col\n",
    "Command:\n",
    "```\n",
    "df_time \\\n",
    "    .filter(F.month('timestamp') == 1) \\\n",
    "    .groupBy(F.dayofmonth('timestamp')) \\\n",
    "    .count() \\\n",
    "    .orderBy('count', ascending=False).show()\n",
    "```\n",
    "Output:\n",
    "```\n",
    "+---------------------+-----+\n",
    "|dayofmonth(Timestamp)|count|\n",
    "+---------------------+-----+\n",
    "|                    1| 1825|\n",
    "|                   12| 1353|\n",
    "|                   15| 1312|\n",
    "|                   13| 1311|\n",
    "|                   26| 1296|\n",
    "|                    6| 1290|\n",
    "|                   17| 1288|\n",
    "|                   18| 1278|\n",
    "|                    5| 1267|\n",
    "|                   20| 1256|\n",
    "|                   16| 1251|\n",
    "|                   23| 1250|\n",
    "|                   10| 1237|\n",
    "|                   11| 1228|\n",
    "|                   27| 1215|\n",
    "|                   19| 1214|\n",
    "|                   30| 1211|\n",
    "|                   31| 1189|\n",
    "|                    9| 1184|\n",
    "|                   25| 1183|\n",
    "+---------------------+-----+\n",
    "only showing top 20 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ac1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_udf = F.udf(dict_city['parser'], returnType=dict_cities['p_ret_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up street column\n",
    "# pick out important columns\n",
    "df_select = df_clean \\\n",
    "    .select(dict_city['selected_cols']) \\\n",
    "    .withColumn(dict_city['p_new_col'], parser_udf(dict_city['p_orig_col'])) \\\n",
    "    .withColumn('city', F.lit(city_proper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bb656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select.write.parquet(f'{gs_bkt}/pq/clean/{dict_cities['formatted']}/{year}/{month}/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619b494f",
   "metadata": {},
   "source": [
    "### check date Jan: pq df\n",
    "Command:\n",
    "```\n",
    "df_pq \\\n",
    "    .filter(F.month('Timestamp') == 1).count()\n",
    "```\n",
    "Output: `1825`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682aea1",
   "metadata": {},
   "source": [
    "### check date Jan1: pq df\n",
    "Command:\n",
    "```\n",
    "df_pq \\\n",
    "    .filter(F.dayofmonth('Timestamp') == 1).count()\n",
    "```\n",
    "Output: `1825`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da80df",
   "metadata": {},
   "source": [
    "### check date here: pq df\n",
    "Command:\n",
    "```\n",
    "df_pq \\\n",
    "    .filter(F.month('Timestamp') == 1) \\\n",
    "    .groupBy(F.dayofmonth('Timestamp')) \\\n",
    "    .count() \\\n",
    "    .orderBy('count', ascending=False).show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4af3715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
